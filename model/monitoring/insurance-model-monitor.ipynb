{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dccb795e-a797-43a6-9b50-05d7e4f57cc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog juan_dev;\n",
    "use schema ml;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be93d52-649e-417f-9882-69e707bfca11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import mlflow\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "class HealthcareModelMonitor:\n",
    "    \"\"\"\n",
    "    Comprehensive model monitoring system specifically designed for your healthcare insurance model.\n",
    "    Updated to use the unified juan_dev.ml schema for all monitoring assets.\n",
    "    \n",
    "    This design provides a cleaner, more maintainable monitoring architecture where\n",
    "    all ML assets live in the same logical space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name=\"juan_dev.ml.healthcare_insurance_model\",\n",
    "                 baseline_table=\"juan_dev.ml.insurance_silver\",\n",
    "                 monitoring_table=\"juan_dev.ml.insurance_predictions\"):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.baseline_table = baseline_table  # Training data (our \"healthy\" reference)\n",
    "        self.monitoring_table = monitoring_table  # Prediction results (what we monitor)\n",
    "        self.schema_name = \"juan_dev.ml\"  # Unified schema for all ML assets\n",
    "        self.workspace = WorkspaceClient()\n",
    "        \n",
    "        # Healthcare-specific monitoring thresholds\n",
    "        self.thresholds = {\n",
    "            \"max_mae_threshold\": 2500,  # Maximum acceptable Mean Absolute Error\n",
    "            \"min_daily_predictions\": 50,  # Minimum predictions per day\n",
    "            \"max_prediction_drift\": 0.20,  # 20% drift in average predictions\n",
    "            \"min_r2_score\": 0.75,  # Minimum acceptable R¬≤ when ground truth available\n",
    "            \"max_demographic_drift\": 0.10  # Maximum acceptable demographic shift\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Healthcare Model Monitor initialized\")\n",
    "        print(f\"   Schema: {self.schema_name}\")\n",
    "        print(f\"   Model: {self.model_name}\")\n",
    "        print(f\"   Baseline: {self.baseline_table}\")\n",
    "        print(f\"   Monitoring: {self.monitoring_table}\")\n",
    "    \n",
    "    def setup_lakehouse_monitoring(self):\n",
    "        \"\"\"\n",
    "        Setup Databricks Lakehouse Monitoring for your healthcare model.\n",
    "        This creates automated monitoring dashboards and drift detection.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Setting up Lakehouse Monitoring for healthcare insurance model...\")\n",
    "        \n",
    "        # First, let's ensure our monitoring table has the right structure\n",
    "        self._prepare_monitoring_table()\n",
    "        \n",
    "        # Create monitoring configuration specifically for healthcare use case\n",
    "        monitor_config = {\n",
    "            \"assets_dir\": \"/juan_dev/ml/monitoring/healthcare_insurance/\",\n",
    "            \"output_schema_name\": self.schema_name,  # Use unified schema\n",
    "            \"baseline_table_name\": self.baseline_table,\n",
    "            \n",
    "            # Slice data by important healthcare demographics for bias monitoring\n",
    "            \"slicing_exprs\": [\n",
    "                \"region\",           # Geographic bias\n",
    "                \"age_group\",        # Age-based bias\n",
    "                \"CASE WHEN smoker THEN 'smoker' ELSE 'non_smoker' END as smoking_status\",  # Smoking bias\n",
    "                \"CASE WHEN bmi > 30 THEN 'obese' WHEN bmi > 25 THEN 'overweight' ELSE 'normal' END as bmi_category\"  # Weight bias\n",
    "            ],\n",
    "            \n",
    "            \"problem_type\": \"PROBLEM_TYPE_REGRESSION\",  # We're predicting continuous charges\n",
    "            \n",
    "            # Configure how to monitor predictions over time\n",
    "            \"inference_log\": {\n",
    "                \"granularities\": [\"1 hour\", \"1 day\", \"1 week\"],  # Monitor at multiple time scales\n",
    "                \"model_id_col\": \"model_name\",  # Identifies which model made the prediction\n",
    "                \"prediction_col\": \"adjusted_prediction\",  # Our main prediction column\n",
    "                \"timestamp_col\": \"prediction_timestamp\",  # When prediction was made\n",
    "                \"label_col\": \"actual_charges\"  # Ground truth (when available from claims data)\n",
    "            },\n",
    "            \n",
    "            # Enable data classification for healthcare compliance\n",
    "            \"data_classification_config\": {\n",
    "                \"enabled\": True  # Important for HIPAA compliance\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Create the monitor\n",
    "            monitor_info = self.workspace.quality_monitors.create(\n",
    "                table_name=self.monitoring_table,\n",
    "                assets_dir=monitor_config[\"assets_dir\"],\n",
    "                output_schema_name=monitor_config[\"output_schema_name\"],\n",
    "                baseline_table_name=monitor_config[\"baseline_table_name\"],\n",
    "                slicing_exprs=monitor_config[\"slicing_exprs\"],\n",
    "                inference_log=monitor_config[\"inference_log\"]\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Lakehouse Monitor created successfully!\")\n",
    "            print(f\"Monitor ID: {monitor_info.monitor_name}\")\n",
    "            print(f\"Dashboard available at: {monitor_config['assets_dir']}\")\n",
    "            print(f\"Monitoring assets stored in: {self.schema_name}\")\n",
    "            \n",
    "            return monitor_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating Lakehouse Monitor: {str(e)}\")\n",
    "            print(\"This might be because:\")\n",
    "            print(\"1. The monitoring table doesn't exist yet (run batch inference first)\")\n",
    "            print(\"2. You don't have permissions to create monitors\")\n",
    "            print(\"3. The table schema doesn't match expected format\")\n",
    "            print(\"Note: Drift detection and alerts will still work without Lakehouse Monitoring\")\n",
    "            return None\n",
    "    \n",
    "    def _prepare_monitoring_table(self):\n",
    "        \"\"\"\n",
    "        Ensure the monitoring table has the right structure for effective monitoring.\n",
    "        This adds columns needed for comprehensive healthcare model monitoring.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Preparing monitoring table structure...\")\n",
    "        \n",
    "        # Check if monitoring table exists\n",
    "        try:\n",
    "            existing_table = spark.table(self.monitoring_table)\n",
    "            print(f\"‚úÖ Monitoring table {self.monitoring_table} exists\")\n",
    "            \n",
    "            # Add age_group column if it doesn't exist (needed for slicing)\n",
    "            if \"age_group\" not in existing_table.columns:\n",
    "                print(\"Adding age_group column for demographic monitoring...\")\n",
    "                \n",
    "                enhanced_table = (\n",
    "                    existing_table\n",
    "                    .withColumn(\"age_group\", \n",
    "                               expr(\"CASE WHEN age < 30 THEN 'young' \" +\n",
    "                                    \"WHEN age < 50 THEN 'middle' \" +\n",
    "                                    \"ELSE 'senior' END\"))\n",
    "                )\n",
    "                \n",
    "                # Update the table with new column\n",
    "                enhanced_table.write.mode(\"overwrite\").saveAsTable(self.monitoring_table)\n",
    "                print(\"‚úÖ Enhanced monitoring table with age_group column\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Monitoring table {self.monitoring_table} not found: {e}\")\n",
    "            print(\"Run batch inference first to create the table\")\n",
    "    \n",
    "    def setup_drift_detection(self):\n",
    "        \"\"\"\n",
    "        Setup comprehensive drift detection for healthcare-specific features.\n",
    "        This monitors both statistical drift and business-relevant drift.\n",
    "        All monitoring views are created in the unified juan_dev.ml schema.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Setting up healthcare-specific drift detection...\")\n",
    "        \n",
    "        # Create a comprehensive drift detection query\n",
    "        drift_detection_query = f\"\"\"\n",
    "        WITH daily_stats AS (\n",
    "            SELECT \n",
    "                DATE(prediction_timestamp) as prediction_date,\n",
    "                model_version,\n",
    "                \n",
    "                -- Prediction statistics\n",
    "                COUNT(*) as daily_prediction_count,\n",
    "                AVG(adjusted_prediction) as avg_daily_prediction,\n",
    "                STDDEV(adjusted_prediction) as std_daily_prediction,\n",
    "                PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY adjusted_prediction) as median_prediction,\n",
    "                \n",
    "                -- Healthcare demographic monitoring (critical for bias detection)\n",
    "                AVG(CASE WHEN smoker THEN 1.0 ELSE 0.0 END) as smoker_rate,\n",
    "                AVG(age) as avg_age,\n",
    "                AVG(bmi) as avg_bmi,\n",
    "                AVG(children) as avg_children,\n",
    "                \n",
    "                -- Regional distribution (important for healthcare equity)\n",
    "                SUM(CASE WHEN UPPER(region) = 'NORTHEAST' THEN 1 ELSE 0 END) / COUNT(*) as northeast_pct,\n",
    "                SUM(CASE WHEN UPPER(region) = 'SOUTHEAST' THEN 1 ELSE 0 END) / COUNT(*) as southeast_pct,\n",
    "                SUM(CASE WHEN UPPER(region) = 'NORTHWEST' THEN 1 ELSE 0 END) / COUNT(*) as northwest_pct,\n",
    "                SUM(CASE WHEN UPPER(region) = 'SOUTHWEST' THEN 1 ELSE 0 END) / COUNT(*) as southwest_pct,\n",
    "                \n",
    "                -- Risk category distribution\n",
    "                SUM(CASE WHEN cost_risk_category = 'high' THEN 1 ELSE 0 END) / COUNT(*) as high_risk_pct,\n",
    "                SUM(CASE WHEN cost_risk_category = 'very_high' THEN 1 ELSE 0 END) / COUNT(*) as very_high_risk_pct,\n",
    "                \n",
    "                -- Performance metrics (when ground truth is available)\n",
    "                CASE WHEN COUNT(actual_charges) > 0 THEN\n",
    "                    AVG(ABS(adjusted_prediction - actual_charges))\n",
    "                ELSE NULL END as daily_mae,\n",
    "                \n",
    "                CASE WHEN COUNT(actual_charges) > 0 THEN\n",
    "                    SQRT(AVG(POWER(adjusted_prediction - actual_charges, 2)))\n",
    "                ELSE NULL END as daily_rmse,\n",
    "                \n",
    "                CASE WHEN COUNT(actual_charges) > 0 THEN\n",
    "                    1 - (SUM(POWER(adjusted_prediction - actual_charges, 2)) / \n",
    "                         SUM(POWER(actual_charges - AVG(actual_charges), 2)))\n",
    "                ELSE NULL END as daily_r2\n",
    "                \n",
    "            FROM {self.monitoring_table}\n",
    "            WHERE prediction_timestamp >= CURRENT_DATE() - INTERVAL 30 DAYS\n",
    "            GROUP BY DATE(prediction_timestamp), model_version\n",
    "        ),\n",
    "        \n",
    "        baseline_stats AS (\n",
    "            SELECT \n",
    "                AVG(charges) as baseline_avg_charges,\n",
    "                STDDEV(charges) as baseline_std_charges,\n",
    "                AVG(CASE WHEN smoker THEN 1.0 ELSE 0.0 END) as baseline_smoker_rate,\n",
    "                AVG(age) as baseline_avg_age,\n",
    "                AVG(bmi) as baseline_avg_bmi,\n",
    "                \n",
    "                -- Baseline regional distribution\n",
    "                SUM(CASE WHEN UPPER(region) = 'NORTHEAST' THEN 1 ELSE 0 END) / COUNT(*) as baseline_northeast_pct,\n",
    "                SUM(CASE WHEN UPPER(region) = 'SOUTHEAST' THEN 1 ELSE 0 END) / COUNT(*) as baseline_southeast_pct,\n",
    "                SUM(CASE WHEN UPPER(region) = 'NORTHWEST' THEN 1 ELSE 0 END) / COUNT(*) as baseline_northwest_pct,\n",
    "                SUM(CASE WHEN UPPER(region) = 'SOUTHWEST' THEN 1 ELSE 0 END) / COUNT(*) as baseline_southwest_pct\n",
    "                \n",
    "            FROM {self.baseline_table}\n",
    "        )\n",
    "        \n",
    "        SELECT \n",
    "            ds.*,\n",
    "            bs.baseline_avg_charges,\n",
    "            bs.baseline_std_charges,\n",
    "            bs.baseline_smoker_rate,\n",
    "            bs.baseline_avg_age,\n",
    "            bs.baseline_avg_bmi,\n",
    "            bs.baseline_northeast_pct,\n",
    "            bs.baseline_southeast_pct,\n",
    "            bs.baseline_northwest_pct,\n",
    "            bs.baseline_southwest_pct,\n",
    "            \n",
    "            -- Statistical drift indicators\n",
    "            ABS(ds.avg_daily_prediction - bs.baseline_avg_charges) / GREATEST(bs.baseline_std_charges, 1) as prediction_drift_zscore,\n",
    "            ABS(ds.avg_daily_prediction - bs.baseline_avg_charges) / GREATEST(bs.baseline_avg_charges, 1) as prediction_drift_percentage,\n",
    "            \n",
    "            -- Demographic drift indicators (critical for healthcare fairness)\n",
    "            ABS(ds.smoker_rate - bs.baseline_smoker_rate) as smoker_rate_drift,\n",
    "            ABS(ds.avg_age - bs.baseline_avg_age) as age_drift,\n",
    "            ABS(ds.avg_bmi - bs.baseline_avg_bmi) as bmi_drift,\n",
    "            \n",
    "            -- Regional distribution drift (important for access equity)\n",
    "            ABS(ds.northeast_pct - bs.baseline_northeast_pct) as northeast_drift,\n",
    "            ABS(ds.southeast_pct - bs.baseline_southeast_pct) as southeast_drift,\n",
    "            ABS(ds.northwest_pct - bs.baseline_northwest_pct) as northwest_drift,\n",
    "            ABS(ds.southwest_pct - bs.baseline_southwest_pct) as southwest_drift,\n",
    "            \n",
    "            -- Composite drift score (overall health indicator)\n",
    "            (ABS(ds.avg_daily_prediction - bs.baseline_avg_charges) / GREATEST(bs.baseline_avg_charges, 1) +\n",
    "             ABS(ds.smoker_rate - bs.baseline_smoker_rate) +\n",
    "             ABS(ds.avg_age - bs.baseline_avg_age) / GREATEST(bs.baseline_avg_age, 1)) / 3 as composite_drift_score,\n",
    "            \n",
    "            -- Alert status flags\n",
    "            CASE WHEN ds.daily_prediction_count < {self.thresholds['min_daily_predictions']} \n",
    "                 THEN 'VOLUME_LOW' ELSE 'VOLUME_OK' END as volume_status,\n",
    "                 \n",
    "            CASE WHEN ds.daily_mae > {self.thresholds['max_mae_threshold']} \n",
    "                 THEN 'ACCURACY_DEGRADED' ELSE 'ACCURACY_OK' END as accuracy_status,\n",
    "                 \n",
    "            CASE WHEN ABS(ds.avg_daily_prediction - bs.baseline_avg_charges) / GREATEST(bs.baseline_avg_charges, 1) > {self.thresholds['max_prediction_drift']}\n",
    "                 THEN 'PREDICTION_DRIFT' ELSE 'PREDICTION_STABLE' END as prediction_drift_status,\n",
    "                 \n",
    "            CASE WHEN ABS(ds.smoker_rate - bs.baseline_smoker_rate) > {self.thresholds['max_demographic_drift']}\n",
    "                 THEN 'DEMOGRAPHIC_DRIFT' ELSE 'DEMOGRAPHIC_STABLE' END as demographic_drift_status,\n",
    "            \n",
    "            CURRENT_TIMESTAMP() as analysis_timestamp\n",
    "                 \n",
    "        FROM daily_stats ds\n",
    "        CROSS JOIN baseline_stats bs\n",
    "        ORDER BY ds.prediction_date DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create drift detection view in the unified schema\n",
    "        drift_view_name = f\"{self.schema_name}.healthcare_drift_detection\"\n",
    "        \n",
    "        try:\n",
    "            # Create the monitoring view\n",
    "            spark.sql(f\"CREATE OR REPLACE VIEW {drift_view_name} AS {drift_detection_query}\")\n",
    "            print(f\"‚úÖ Created drift detection view: {drift_view_name}\")\n",
    "            \n",
    "            # Test the view and show sample results\n",
    "            drift_results = spark.sql(f\"SELECT * FROM {drift_view_name} LIMIT 5\")\n",
    "            drift_count = drift_results.count()\n",
    "            \n",
    "            if drift_count > 0:\n",
    "                print(f\"‚úÖ Drift detection operational - analyzing {drift_count} recent monitoring periods\")\n",
    "                print(\"Sample drift analysis:\")\n",
    "                drift_results.select(\n",
    "                    \"prediction_date\", \"daily_prediction_count\", \n",
    "                    \"prediction_drift_percentage\", \"composite_drift_score\",\n",
    "                    \"volume_status\", \"prediction_drift_status\", \"demographic_drift_status\"\n",
    "                ).show(truncate=False)\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  No recent prediction data found for drift analysis\")\n",
    "                print(\"Run batch inference first to generate monitoring data\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating drift detection: {e}\")\n",
    "            print(\"Make sure the monitoring table exists and has recent data\")\n",
    "        \n",
    "        return drift_view_name\n",
    "    \n",
    "    def setup_performance_alerts(self):\n",
    "        \"\"\"\n",
    "        Setup automated alerts for healthcare model performance issues.\n",
    "        These alerts help catch problems before they impact business decisions.\n",
    "        All alert views are created in the unified juan_dev.ml schema.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Setting up healthcare-specific performance alerts...\")\n",
    "        \n",
    "        # Define healthcare-specific alert conditions\n",
    "        alert_conditions = [\n",
    "            {\n",
    "                \"name\": \"high_mae_alert\",\n",
    "                \"description\": \"Model prediction error exceeds healthcare accuracy standards\",\n",
    "                \"condition\": f\"daily_mae > {self.thresholds['max_mae_threshold']}\",\n",
    "                \"severity\": \"HIGH\",\n",
    "                \"message\": f\"Model MAE exceeded ${self.thresholds['max_mae_threshold']} threshold - may impact underwriting decisions\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"prediction_volume_drop\",\n",
    "                \"description\": \"Daily prediction volume below expected threshold\",\n",
    "                \"condition\": f\"daily_prediction_count < {self.thresholds['min_daily_predictions']}\",\n",
    "                \"severity\": \"MEDIUM\", \n",
    "                \"message\": f\"Daily prediction volume below {self.thresholds['min_daily_predictions']} - check data pipeline health\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"prediction_drift_alert\",\n",
    "                \"description\": \"Significant drift in average predictions detected\",\n",
    "                \"condition\": f\"prediction_drift_zscore > 2.0\",\n",
    "                \"severity\": \"HIGH\",\n",
    "                \"message\": \"Significant prediction drift detected - model may need retraining\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"demographic_bias_alert\", \n",
    "                \"description\": \"Potential bias detected in demographic predictions\",\n",
    "                \"condition\": f\"smoker_rate_drift > {self.thresholds['max_demographic_drift']}\",\n",
    "                \"severity\": \"HIGH\",\n",
    "                \"message\": \"Smoking rate distribution has shifted significantly - check for selection bias\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"regional_distribution_alert\",\n",
    "                \"description\": \"Regional distribution of predictions has changed\",\n",
    "                \"condition\": \"ABS(northeast_pct + southeast_pct + northwest_pct + southwest_pct - 1.0) > 0.05\",\n",
    "                \"severity\": \"MEDIUM\",\n",
    "                \"message\": \"Regional distribution has shifted - verify data source coverage\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Create alert monitoring query\n",
    "        alert_query = f\"\"\"\n",
    "        SELECT \n",
    "            prediction_date,\n",
    "            model_version,\n",
    "            daily_prediction_count,\n",
    "            avg_daily_prediction,\n",
    "            daily_mae,\n",
    "            composite_drift_score,\n",
    "            \n",
    "            -- Specific alert conditions with business context\n",
    "            CASE \n",
    "                WHEN volume_status = 'VOLUME_LOW' THEN 'LOW_PREDICTION_VOLUME'\n",
    "                WHEN accuracy_status = 'ACCURACY_DEGRADED' THEN 'HIGH_PREDICTION_ERROR'\n",
    "                WHEN prediction_drift_status = 'PREDICTION_DRIFT' THEN 'SIGNIFICANT_PREDICTION_DRIFT'\n",
    "                WHEN demographic_drift_status = 'DEMOGRAPHIC_DRIFT' THEN 'DEMOGRAPHIC_BIAS_RISK'\n",
    "                WHEN composite_drift_score > 0.3 THEN 'MULTIPLE_DRIFT_INDICATORS'\n",
    "                ELSE 'HEALTHY'\n",
    "            END as primary_alert_type,\n",
    "            \n",
    "            -- Alert severity based on business impact\n",
    "            CASE \n",
    "                WHEN accuracy_status = 'ACCURACY_DEGRADED' AND daily_mae > {self.thresholds['max_mae_threshold'] * 1.5} THEN 'CRITICAL'\n",
    "                WHEN demographic_drift_status = 'DEMOGRAPHIC_DRIFT' THEN 'HIGH'\n",
    "                WHEN prediction_drift_status = 'PREDICTION_DRIFT' THEN 'HIGH'\n",
    "                WHEN volume_status = 'VOLUME_LOW' THEN 'MEDIUM'\n",
    "                WHEN composite_drift_score > 0.3 THEN 'MEDIUM'\n",
    "                ELSE 'LOW'\n",
    "            END as alert_severity,\n",
    "            \n",
    "            -- Business impact description\n",
    "            CASE \n",
    "                WHEN accuracy_status = 'ACCURACY_DEGRADED' THEN \n",
    "                    CONCAT('Prediction errors exceed $', CAST({self.thresholds['max_mae_threshold']} AS STRING), ' - may impact underwriting decisions')\n",
    "                WHEN demographic_drift_status = 'DEMOGRAPHIC_DRIFT' THEN \n",
    "                    'Demographic distribution has shifted significantly - potential bias concern'\n",
    "                WHEN prediction_drift_status = 'PREDICTION_DRIFT' THEN \n",
    "                    'Average predictions have drifted from baseline - model may need retraining'\n",
    "                WHEN volume_status = 'VOLUME_LOW' THEN \n",
    "                    'Daily prediction volume below threshold - check data pipeline health'\n",
    "                ELSE 'Model operating within normal parameters'\n",
    "            END as business_impact_description,\n",
    "            \n",
    "            -- Recommended actions\n",
    "            CASE \n",
    "                WHEN accuracy_status = 'ACCURACY_DEGRADED' THEN 'Investigate model performance and consider immediate retraining'\n",
    "                WHEN demographic_drift_status = 'DEMOGRAPHIC_DRIFT' THEN 'Review data sources and conduct bias analysis'\n",
    "                WHEN prediction_drift_status = 'PREDICTION_DRIFT' THEN 'Schedule model retraining and validate feature engineering'\n",
    "                WHEN volume_status = 'VOLUME_LOW' THEN 'Check upstream data pipelines and batch job health'\n",
    "                ELSE 'Continue routine monitoring'\n",
    "            END as recommended_action,\n",
    "            \n",
    "            CURRENT_TIMESTAMP() as alert_timestamp\n",
    "            \n",
    "        FROM {self.schema_name}.healthcare_drift_detection\n",
    "        WHERE prediction_date >= CURRENT_DATE() - INTERVAL 7 DAYS\n",
    "          AND (\n",
    "              volume_status != 'VOLUME_OK' OR\n",
    "              accuracy_status != 'ACCURACY_OK' OR\n",
    "              prediction_drift_status != 'PREDICTION_STABLE' OR\n",
    "              demographic_drift_status != 'DEMOGRAPHIC_STABLE' OR\n",
    "              composite_drift_score > 0.2\n",
    "          )\n",
    "        ORDER BY \n",
    "            CASE alert_severity \n",
    "                WHEN 'CRITICAL' THEN 1 \n",
    "                WHEN 'HIGH' THEN 2 \n",
    "                WHEN 'MEDIUM' THEN 3 \n",
    "                ELSE 4 \n",
    "            END,\n",
    "            prediction_date DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create alerts view in the unified schema\n",
    "        alerts_view_name = f\"{self.schema_name}.healthcare_model_alerts\"\n",
    "        \n",
    "        try:\n",
    "            spark.sql(f\"CREATE OR REPLACE VIEW {alerts_view_name} AS {alert_query}\")\n",
    "            print(f\"‚úÖ Created alerts monitoring view: {alerts_view_name}\")\n",
    "            \n",
    "            # Check for current alerts\n",
    "            current_alerts = spark.sql(f\"SELECT * FROM {alerts_view_name}\")\n",
    "            alert_count = current_alerts.count()\n",
    "            \n",
    "            if alert_count > 0:\n",
    "                print(f\"‚ö†Ô∏è  Found {alert_count} active alerts:\")\n",
    "                current_alerts.select(\n",
    "                    \"prediction_date\", \"primary_alert_type\", \"alert_severity\", \n",
    "                    \"business_impact_description\", \"recommended_action\"\n",
    "                ).show(truncate=False)\n",
    "            else:\n",
    "                print(\"‚úÖ No active alerts - model is performing within expected parameters\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error setting up alerts: {e}\")\n",
    "        \n",
    "        return alert_conditions, alerts_view_name\n",
    "    \n",
    "    def create_performance_dashboard(self):\n",
    "        \"\"\"\n",
    "        Create a comprehensive performance dashboard that provides executive-level\n",
    "        insights into your healthcare model's business impact and operational health.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Creating executive performance dashboard...\")\n",
    "        \n",
    "        dashboard_query = f\"\"\"\n",
    "        WITH performance_summary AS (\n",
    "            SELECT \n",
    "                -- Time period analysis\n",
    "                'Last 7 Days' as reporting_period,\n",
    "                MIN(prediction_date) as period_start,\n",
    "                MAX(prediction_date) as period_end,\n",
    "                COUNT(DISTINCT prediction_date) as active_days,\n",
    "                \n",
    "                -- Volume and operational metrics\n",
    "                SUM(daily_prediction_count) as total_predictions,\n",
    "                AVG(daily_prediction_count) as avg_daily_predictions,\n",
    "                MIN(daily_prediction_count) as min_daily_predictions,\n",
    "                MAX(daily_prediction_count) as max_daily_predictions,\n",
    "                \n",
    "                -- Financial impact metrics\n",
    "                AVG(avg_daily_prediction) as avg_predicted_cost,\n",
    "                STDDEV(avg_daily_prediction) as prediction_volatility,\n",
    "                SUM(daily_prediction_count * avg_daily_prediction) as total_predicted_exposure,\n",
    "                \n",
    "                -- Quality and performance metrics\n",
    "                AVG(daily_mae) as avg_prediction_error,\n",
    "                AVG(daily_rmse) as avg_rmse,\n",
    "                AVG(daily_r2) as avg_r2_score,\n",
    "                \n",
    "                -- Drift and stability metrics\n",
    "                AVG(composite_drift_score) as avg_composite_drift,\n",
    "                MAX(composite_drift_score) as max_composite_drift,\n",
    "                AVG(prediction_drift_percentage) as avg_prediction_drift,\n",
    "                \n",
    "                -- Operational health indicators\n",
    "                COUNT(CASE WHEN volume_status != 'VOLUME_OK' THEN 1 END) as days_with_volume_issues,\n",
    "                COUNT(CASE WHEN accuracy_status != 'ACCURACY_OK' THEN 1 END) as days_with_accuracy_issues,\n",
    "                COUNT(CASE WHEN prediction_drift_status != 'PREDICTION_STABLE' THEN 1 END) as days_with_drift_issues,\n",
    "                COUNT(CASE WHEN demographic_drift_status != 'DEMOGRAPHIC_STABLE' THEN 1 END) as days_with_bias_concerns,\n",
    "                \n",
    "                -- Demographic fairness and equity metrics\n",
    "                AVG(smoker_rate) as avg_smoker_rate,\n",
    "                STDDEV(smoker_rate) as smoker_rate_stability,\n",
    "                MAX(smoker_rate_drift) as max_smoker_rate_drift,\n",
    "                AVG(age_drift) as avg_age_drift,\n",
    "                AVG(bmi_drift) as avg_bmi_drift,\n",
    "                \n",
    "                -- Regional coverage and equity\n",
    "                AVG(northeast_pct) as avg_northeast_coverage,\n",
    "                AVG(southeast_pct) as avg_southeast_coverage,\n",
    "                AVG(northwest_pct) as avg_northwest_coverage,\n",
    "                AVG(southwest_pct) as avg_southwest_coverage,\n",
    "                \n",
    "                -- Risk distribution metrics\n",
    "                AVG(high_risk_pct) as avg_high_risk_percentage,\n",
    "                AVG(very_high_risk_pct) as avg_very_high_risk_percentage\n",
    "                \n",
    "            FROM {self.schema_name}.healthcare_drift_detection\n",
    "            WHERE prediction_date >= CURRENT_DATE() - INTERVAL 7 DAYS\n",
    "        )\n",
    "        \n",
    "        SELECT \n",
    "            *,\n",
    "            -- Executive summary ratings\n",
    "            CASE \n",
    "                WHEN avg_prediction_error IS NULL THEN 'MONITORING_ONLY'\n",
    "                WHEN avg_prediction_error <= {self.thresholds['max_mae_threshold']} * 0.7 THEN 'EXCELLENT'\n",
    "                WHEN avg_prediction_error <= {self.thresholds['max_mae_threshold']} THEN 'GOOD'\n",
    "                WHEN avg_prediction_error <= {self.thresholds['max_mae_threshold']} * 1.2 THEN 'ACCEPTABLE'\n",
    "                ELSE 'NEEDS_ATTENTION'\n",
    "            END as performance_rating,\n",
    "            \n",
    "            CASE \n",
    "                WHEN days_with_volume_issues = 0 AND days_with_accuracy_issues = 0 AND days_with_drift_issues = 0 THEN 'STABLE'\n",
    "                WHEN days_with_accuracy_issues > 0 OR days_with_drift_issues > 2 THEN 'UNSTABLE'\n",
    "                ELSE 'MINOR_ISSUES'\n",
    "            END as operational_stability,\n",
    "            \n",
    "            CASE \n",
    "                WHEN max_smoker_rate_drift <= {self.thresholds['max_demographic_drift']} * 0.5 THEN 'EXCELLENT'\n",
    "                WHEN max_smoker_rate_drift <= {self.thresholds['max_demographic_drift']} THEN 'GOOD'\n",
    "                ELSE 'REQUIRES_REVIEW'\n",
    "            END as fairness_rating,\n",
    "            \n",
    "            -- Business impact and recommendations\n",
    "            CASE \n",
    "                WHEN avg_prediction_error > {self.thresholds['max_mae_threshold']} THEN 'IMMEDIATE_RETRAINING_RECOMMENDED'\n",
    "                WHEN avg_composite_drift > 0.3 THEN 'SCHEDULE_RETRAINING_SOON'\n",
    "                WHEN days_with_drift_issues > 3 THEN 'MONITOR_CLOSELY'\n",
    "                ELSE 'CONTINUE_ROUTINE_OPERATIONS'\n",
    "            END as business_recommendation,\n",
    "            \n",
    "            -- Financial impact assessment\n",
    "            CASE \n",
    "                WHEN avg_prediction_error IS NOT NULL AND avg_prediction_error > {self.thresholds['max_mae_threshold']} THEN 'HIGH_FINANCIAL_RISK'\n",
    "                WHEN prediction_volatility > avg_predicted_cost * 0.3 THEN 'MODERATE_FINANCIAL_RISK'\n",
    "                ELSE 'LOW_FINANCIAL_RISK'\n",
    "            END as financial_risk_assessment,\n",
    "            \n",
    "            CURRENT_TIMESTAMP() as dashboard_generated_timestamp\n",
    "            \n",
    "        FROM performance_summary\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create dashboard view in the unified schema\n",
    "        dashboard_view_name = f\"{self.schema_name}.model_performance_dashboard\"\n",
    "        \n",
    "        try:\n",
    "            spark.sql(f\"CREATE OR REPLACE VIEW {dashboard_view_name} AS {dashboard_query}\")\n",
    "            print(f\"‚úÖ Created performance dashboard: {dashboard_view_name}\")\n",
    "            \n",
    "            # Display current dashboard summary\n",
    "            dashboard_data = spark.sql(f\"SELECT * FROM {dashboard_view_name}\")\n",
    "            if dashboard_data.count() > 0:\n",
    "                print(\"üìä Executive Performance Summary:\")\n",
    "                dashboard_data.select(\n",
    "                    \"reporting_period\", \"total_predictions\", \"avg_predicted_cost\",\n",
    "                    \"performance_rating\", \"operational_stability\", \"fairness_rating\",\n",
    "                    \"business_recommendation\", \"financial_risk_assessment\"\n",
    "                ).show(truncate=False)\n",
    "                \n",
    "                # Show detailed metrics\n",
    "                print(\"üìà Detailed Metrics:\")\n",
    "                dashboard_data.select(\n",
    "                    \"avg_prediction_error\", \"avg_composite_drift\", \n",
    "                    \"days_with_accuracy_issues\", \"days_with_drift_issues\", \"days_with_bias_concerns\"\n",
    "                ).show(truncate=False)\n",
    "            \n",
    "            return {\"success\": True, \"view_name\": dashboard_view_name}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to create performance dashboard: {str(e)}\")\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    def run_comprehensive_health_check(self):\n",
    "        \"\"\"\n",
    "        Run a complete health check of your healthcare model monitoring system.\n",
    "        This verifies everything is working correctly within the unified schema.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"üè• Running Comprehensive Healthcare Model Health Check...\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        health_status = {\n",
    "            \"monitoring_table_exists\": False,\n",
    "            \"baseline_table_exists\": False, \n",
    "            \"recent_predictions\": False,\n",
    "            \"drift_detection_working\": False,\n",
    "            \"alerts_configured\": False,\n",
    "            \"dashboard_available\": False,\n",
    "            \"overall_health\": \"UNKNOWN\"\n",
    "        }\n",
    "        \n",
    "        # Check 1: Monitoring table exists and has data\n",
    "        try:\n",
    "            monitoring_df = spark.table(self.monitoring_table)\n",
    "            row_count = monitoring_df.count()\n",
    "            health_status[\"monitoring_table_exists\"] = True\n",
    "            print(f\"‚úÖ Monitoring table exists with {row_count:,} records\")\n",
    "            \n",
    "            # Check for recent data\n",
    "            recent_data = monitoring_df.filter(\n",
    "                col(\"prediction_timestamp\") >= expr(\"CURRENT_DATE() - INTERVAL 7 DAYS\")\n",
    "            ).count()\n",
    "            \n",
    "            if recent_data > 0:\n",
    "                health_status[\"recent_predictions\"] = True\n",
    "                print(f\"‚úÖ Found {recent_data:,} recent predictions in last 7 days\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  No recent predictions found - run batch inference\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Monitoring table check failed: {e}\")\n",
    "        \n",
    "        # Check 2: Baseline table exists\n",
    "        try:\n",
    "            baseline_df = spark.table(self.baseline_table)\n",
    "            baseline_count = baseline_df.count()\n",
    "            health_status[\"baseline_table_exists\"] = True\n",
    "            print(f\"‚úÖ Baseline table exists with {baseline_count:,} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Baseline table check failed: {e}\")\n",
    "        \n",
    "        # Check 3: Drift detection (only if view exists)\n",
    "        try:\n",
    "            # First check if the view exists\n",
    "            existing_views = spark.sql(f\"SHOW VIEWS IN {self.schema_name}\")\n",
    "            view_names = [row.viewName for row in existing_views.collect()]\n",
    "            \n",
    "            if \"healthcare_drift_detection\" in view_names:\n",
    "                drift_df = spark.sql(f\"SELECT * FROM {self.schema_name}.healthcare_drift_detection LIMIT 1\")\n",
    "                if drift_df.count() > 0:\n",
    "                    health_status[\"drift_detection_working\"] = True\n",
    "                    print(\"‚úÖ Drift detection is working\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è  Drift detection view exists but no data\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Drift detection not yet configured\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Drift detection check failed: {e}\")\n",
    "        \n",
    "        # Check 4: Alerts (only if view exists)\n",
    "        try:\n",
    "            existing_views = spark.sql(f\"SHOW VIEWS IN {self.schema_name}\")\n",
    "            view_names = [row.viewName for row in existing_views.collect()]\n",
    "            \n",
    "            if \"healthcare_model_alerts\" in view_names:\n",
    "                alerts_df = spark.sql(f\"SELECT * FROM {self.schema_name}.healthcare_model_alerts LIMIT 1\")\n",
    "                health_status[\"alerts_configured\"] = True\n",
    "                print(\"‚úÖ Alerts system is configured\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Alerts system not yet configured\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Alerts check failed: {e}\")\n",
    "        \n",
    "        # Check 5: Dashboard (only if view exists)\n",
    "        try:\n",
    "            existing_views = spark.sql(f\"SHOW VIEWS IN {self.schema_name}\")\n",
    "            view_names = [row.viewName for row in existing_views.collect()]\n",
    "            \n",
    "            if \"model_performance_dashboard\" in view_names:\n",
    "                dashboard_df = spark.sql(f\"SELECT * FROM {self.schema_name}.model_performance_dashboard LIMIT 1\")\n",
    "                health_status[\"dashboard_available\"] = True\n",
    "                print(\"‚úÖ Performance dashboard is available\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Performance dashboard not yet configured\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Dashboard check failed: {e}\")\n",
    "        \n",
    "        # Overall health assessment\n",
    "        checks_passed = sum([\n",
    "            health_status[\"monitoring_table_exists\"],\n",
    "            health_status[\"baseline_table_exists\"],\n",
    "            health_status[\"recent_predictions\"],\n",
    "            health_status[\"drift_detection_working\"],\n",
    "            health_status[\"alerts_configured\"],\n",
    "            health_status[\"dashboard_available\"]\n",
    "        ])\n",
    "        \n",
    "        if checks_passed >= 5:\n",
    "            health_status[\"overall_health\"] = \"HEALTHY\"\n",
    "            print(\"\\nüéâ Overall Status: HEALTHY - Monitoring system is fully operational!\")\n",
    "        elif checks_passed >= 3:\n",
    "            health_status[\"overall_health\"] = \"PARTIALLY_HEALTHY\"\n",
    "            print(\"\\n‚ö†Ô∏è  Overall Status: PARTIALLY HEALTHY - Some components need setup\")\n",
    "        else:\n",
    "            health_status[\"overall_health\"] = \"UNHEALTHY\"\n",
    "            print(\"\\n‚ùå Overall Status: UNHEALTHY - Monitoring system needs configuration\")\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        return health_status\n",
    "    \n",
    "    def setup_complete_monitoring_system(self):\n",
    "        \"\"\"\n",
    "        One-stop method to set up the complete monitoring infrastructure.\n",
    "        This creates all monitoring components in the correct order.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"üöÄ Setting up Complete Healthcare Model Monitoring System\")\n",
    "        print(\"All monitoring assets will be created in the unified juan_dev.ml schema\")\n",
    "        print(\"=\" * 75)\n",
    "        \n",
    "        setup_results = {}\n",
    "        \n",
    "        # Step 1: Health check foundation\n",
    "        print(\"\\nStep 1: Validating monitoring foundation...\")\n",
    "        health_status = self.run_comprehensive_health_check()\n",
    "        setup_results[\"foundation\"] = health_status\n",
    "        \n",
    "        if not health_status[\"monitoring_table_exists\"]:\n",
    "            print(\"‚ùå Cannot proceed without monitoring table. Run batch inference first.\")\n",
    "            return setup_results\n",
    "        \n",
    "        # Step 2: Set up drift detection\n",
    "        print(\"\\nStep 2: Setting up drift detection system...\")\n",
    "        try:\n",
    "            drift_view = self.setup_drift_detection()\n",
    "            setup_results[\"drift_detection\"] = {\"success\": True, \"view\": drift_view}\n",
    "        except Exception as e:\n",
    "            setup_results[\"drift_detection\"] = {\"success\": False, \"error\": str(e)}\n",
    "        \n",
    "        # Step 3: Set up alerts\n",
    "        print(\"\\nStep 3: Setting up intelligent alerts...\")\n",
    "        try:\n",
    "            alert_conditions, alerts_view = self.setup_performance_alerts()\n",
    "            setup_results[\"alerts\"] = {\n",
    "                \"success\": True, \n",
    "                \"view\": alerts_view, \n",
    "                \"conditions\": len(alert_conditions)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            setup_results[\"alerts\"] = {\"success\": False, \"error\": str(e)}\n",
    "        \n",
    "        # Step 4: Set up dashboard\n",
    "        print(\"\\nStep 4: Creating performance dashboard...\")\n",
    "        try:\n",
    "            dashboard_result = self.create_performance_dashboard()\n",
    "            setup_results[\"dashboard\"] = dashboard_result\n",
    "        except Exception as e:\n",
    "            setup_results[\"dashboard\"] = {\"success\": False, \"error\": str(e)}\n",
    "        \n",
    "        # Step 5: Try Lakehouse Monitoring (optional)\n",
    "        print(\"\\nStep 5: Attempting Lakehouse Monitoring setup...\")\n",
    "        try:\n",
    "            monitor_info = self.setup_lakehouse_monitoring()\n",
    "            if monitor_info:\n",
    "                setup_results[\"lakehouse_monitoring\"] = {\"success\": True, \"monitor\": monitor_info}\n",
    "            else:\n",
    "                setup_results[\"lakehouse_monitoring\"] = {\"success\": False, \"note\": \"Requires additional permissions\"}\n",
    "        except Exception as e:\n",
    "            setup_results[\"lakehouse_monitoring\"] = {\"success\": False, \"error\": str(e)}\n",
    "        \n",
    "        # Final validation\n",
    "        print(\"\\nStep 6: Final system validation...\")\n",
    "        final_health = self.run_comprehensive_health_check()\n",
    "        setup_results[\"final_health\"] = final_health\n",
    "        \n",
    "        # Print setup summary\n",
    "        self._print_setup_summary(setup_results)\n",
    "        \n",
    "        return setup_results\n",
    "    \n",
    "    def _print_setup_summary(self, setup_results):\n",
    "        \"\"\"Print a comprehensive summary of the monitoring setup.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 75)\n",
    "    \n",
    "    def diagnose_and_fix_setup_issues(self):\n",
    "        \"\"\"\n",
    "        Diagnose common setup issues and provide specific fixes.\n",
    "        Run this if you encounter errors during monitoring setup.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"üîß HEALTHCARE MONITORING SYSTEM DIAGNOSTICS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        issues_found = []\n",
    "        fixes_applied = []\n",
    "        \n",
    "        # Check 1: Schema exists and is accessible\n",
    "        print(\"\\n1. Checking schema accessibility...\")\n",
    "        try:\n",
    "            schemas = spark.sql(\"SHOW TABLES IN juan_dev.ml\")\n",
    "            if schemas.count() > 0:\n",
    "                print(\"‚úÖ juan_dev catalog is accessible\")\n",
    "                \n",
    "                # Check if ml schema exists\n",
    "                ml_tables = spark.sql(\"SHOW TABLES IN juan_dev.ml\")\n",
    "                print(f\"‚úÖ juan_dev.ml schema exists with {ml_tables.count()} objects\")\n",
    "            else:\n",
    "                issues_found.append(\"Cannot access juan_dev catalog\")\n",
    "                print(\"‚ùå Cannot access juan_dev catalog - check permissions\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            issues_found.append(f\"Schema access error: {str(e)}\")\n",
    "            print(f\"‚ùå Schema access error: {e}\")\n",
    "        \n",
    "        # Check 2: Required tables exist\n",
    "        print(\"\\n2. Checking required tables...\")\n",
    "        required_tables = [\n",
    "            (\"insurance_silver\", \"Training baseline data\"),\n",
    "            (\"insurance_predictions\", \"Live prediction results\")\n",
    "        ]\n",
    "        \n",
    "        for table_name, description in required_tables:\n",
    "            try:\n",
    "                full_table_name = f\"juan_dev.ml.{table_name}\"\n",
    "                df = spark.table(full_table_name)\n",
    "                count = df.count()\n",
    "                print(f\"‚úÖ {table_name}: {count:,} records ({description})\")\n",
    "                \n",
    "                # Check if predictions table has recent data\n",
    "                if table_name == \"insurance_predictions\":\n",
    "                    recent_count = df.filter(\n",
    "                        col(\"prediction_timestamp\") >= expr(\"CURRENT_DATE() - INTERVAL 1 DAYS\")\n",
    "                    ).count()\n",
    "                    \n",
    "                    if recent_count > 0:\n",
    "                        print(f\"   ‚úÖ Has {recent_count:,} recent predictions (last 24 hours)\")\n",
    "                    else:\n",
    "                        issues_found.append(\"No recent prediction data for monitoring\")\n",
    "                        print(\"   ‚ö†Ô∏è  No recent predictions - run batch inference first\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                issues_found.append(f\"Missing table {table_name}: {str(e)}\")\n",
    "                print(f\"‚ùå {table_name}: Not found - {e}\")\n",
    "        \n",
    "        # Check 3: Column requirements\n",
    "        print(\"\\n3. Checking column requirements...\")\n",
    "        try:\n",
    "            pred_df = spark.table(\"juan_dev.ml.insurance_predictions\")\n",
    "            required_columns = [\n",
    "                \"prediction_timestamp\", \"adjusted_prediction\", \"model_name\", \n",
    "                \"sex\", \"region\", \"smoker\", \"age\", \"bmi\", \"cost_risk_category\"\n",
    "            ]\n",
    "            \n",
    "            missing_columns = [col for col in required_columns if col not in pred_df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                issues_found.append(f\"Monitoring table missing columns: {missing_columns}\")\n",
    "                print(f\"‚ùå Missing required columns: {missing_columns}\")\n",
    "                print(\"   üí° Run updated batch inference to add missing columns\")\n",
    "            else:\n",
    "                print(\"‚úÖ All required columns present for monitoring\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not check column requirements: {e}\")\n",
    "        \n",
    "        # Check 4: Existing monitoring views\n",
    "        print(\"\\n4. Checking existing monitoring views...\")\n",
    "        try:\n",
    "            views = spark.sql(f\"SHOW VIEWS IN juan_dev.ml\")\n",
    "            view_names = [row.viewName for row in views.collect()]\n",
    "            \n",
    "            monitoring_views = [name for name in view_names if 'healthcare' in name or 'monitoring' in name or 'dashboard' in name]\n",
    "            \n",
    "            if monitoring_views:\n",
    "                print(\"‚úÖ Found existing monitoring views:\")\n",
    "                for view in monitoring_views:\n",
    "                    print(f\"   - {view}\")\n",
    "            else:\n",
    "                print(\"‚ÑπÔ∏è  No monitoring views found yet (this is normal for first setup)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not check views: {e}\")\n",
    "        \n",
    "        # Provide specific fixes\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üîß DIAGNOSTIC SUMMARY AND FIXES\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        if not issues_found:\n",
    "            print(\"üéâ No issues found! Your system is ready for monitoring setup.\")\n",
    "            print(\"\\nNext step: Run monitor.setup_complete_monitoring_system()\")\n",
    "        else:\n",
    "            print(f\"Found {len(issues_found)} issues that need attention:\")\n",
    "            for i, issue in enumerate(issues_found, 1):\n",
    "                print(f\"\\n{i}. ‚ùå {issue}\")\n",
    "                \n",
    "                # Provide specific fixes\n",
    "                if \"No recent prediction data\" in issue:\n",
    "                    print(\"   üí° FIX: Run batch inference first:\")\n",
    "                    print(\"      batch_inference.run_batch_inference(\")\n",
    "                    print(\"          input_table='juan_dev.ml.insurance_silver',\")\n",
    "                    print(\"          output_table='juan_dev.ml.insurance_predictions')\")\n",
    "                \n",
    "                elif \"Missing table\" in issue and \"insurance_predictions\" in issue:\n",
    "                    print(\"   üí° FIX: Create predictions table by running batch inference\")\n",
    "                \n",
    "                elif \"Missing required columns\" in issue:\n",
    "                    print(\"   üí° FIX: Update batch inference with latest code that includes all columns\")\n",
    "                \n",
    "                elif \"Cannot access\" in issue:\n",
    "                    print(\"   üí° FIX: Check Unity Catalog permissions for juan_dev.ml schema\")\n",
    "        \n",
    "        return {\n",
    "            \"issues_found\": issues_found,\n",
    "            \"fixes_applied\": fixes_applied,\n",
    "            \"ready_for_setup\": len(issues_found) == 0\n",
    "        }\n",
    "    \n",
    "    def quick_monitoring_setup(self):\n",
    "        \"\"\"\n",
    "        Simplified setup method that handles common issues automatically.\n",
    "        Use this if the full setup encounters problems.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"üöÄ Quick Healthcare Monitoring Setup\")\n",
    "        print(\"This simplified setup works around common configuration issues\")\n",
    "        print(\"=\" * 65)\n",
    "        \n",
    "        setup_success = True\n",
    "        \n",
    "        # Step 1: Basic validation\n",
    "        print(\"\\nStep 1: Running diagnostics...\")\n",
    "        diagnostic_results = self.diagnose_and_fix_setup_issues()\n",
    "        \n",
    "        if not diagnostic_results[\"ready_for_setup\"]:\n",
    "            print(\"\\n‚ùå Cannot proceed with setup - please address the issues above first\")\n",
    "            return {\"success\": False, \"diagnostics\": diagnostic_results}\n",
    "        \n",
    "        # Step 2: Create drift detection view with error handling\n",
    "        print(\"\\nStep 2: Setting up drift detection...\")\n",
    "        try:\n",
    "            drift_view = self.setup_drift_detection()\n",
    "            print(f\"‚úÖ Drift detection created: {drift_view}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Drift detection failed: {e}\")\n",
    "            setup_success = False\n",
    "        \n",
    "        # Step 3: Create alerts view\n",
    "        print(\"\\nStep 3: Setting up alerts...\")\n",
    "        try:\n",
    "            alert_conditions, alerts_view = self.setup_performance_alerts()\n",
    "            print(f\"‚úÖ Alert system created: {alerts_view}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Alert setup failed: {e}\")\n",
    "            setup_success = False\n",
    "        \n",
    "        # Step 4: Create dashboard\n",
    "        print(\"\\nStep 4: Setting up dashboard...\")\n",
    "        try:\n",
    "            dashboard_result = self.create_performance_dashboard()\n",
    "            if dashboard_result.get(\"success\"):\n",
    "                print(f\"‚úÖ Dashboard created: {dashboard_result['view_name']}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Dashboard failed: {dashboard_result.get('error')}\")\n",
    "                setup_success = False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Dashboard setup failed: {e}\")\n",
    "            setup_success = False\n",
    "        \n",
    "        # Final status\n",
    "        if setup_success:\n",
    "            print(f\"\\nüéâ Quick setup completed successfully!\")\n",
    "            print(f\"All monitoring views created in {self.schema_name}\")\n",
    "            \n",
    "            # Show what was created\n",
    "            try:\n",
    "                views = spark.sql(f\"SHOW VIEWS IN {self.schema_name}\")\n",
    "                monitoring_views = [row.viewName for row in views.collect() \n",
    "                                  if any(keyword in row.viewName.lower() \n",
    "                                       for keyword in ['healthcare', 'monitoring', 'dashboard', 'alert'])]\n",
    "                \n",
    "                if monitoring_views:\n",
    "                    print(f\"\\nüìã Created monitoring views:\")\n",
    "                    for view in monitoring_views:\n",
    "                        print(f\"   ‚Ä¢ {self.schema_name}.{view}\")\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Setup completed with some errors\")\n",
    "            print(\"Check the error messages above for specific issues\")\n",
    "        \n",
    "        return {\n",
    "            \"success\": setup_success,\n",
    "            \"diagnostics\": diagnostic_results,\n",
    "            \"monitoring_ready\": setup_success\n",
    "        }\n",
    "        print(\"üè• HEALTHCARE MODEL MONITORING SETUP COMPLETE\")\n",
    "        print(\"=\" * 75)\n",
    "        \n",
    "        # Component status\n",
    "        components = [\n",
    "            (\"Foundation\", setup_results.get(\"foundation\", {}).get(\"overall_health\", \"Unknown\")),\n",
    "            (\"Drift Detection\", \"‚úÖ Operational\" if setup_results.get(\"drift_detection\", {}).get(\"success\") else \"‚ùå Failed\"),\n",
    "            (\"Alert System\", \"‚úÖ Operational\" if setup_results.get(\"alerts\", {}).get(\"success\") else \"‚ùå Failed\"),\n",
    "            (\"Performance Dashboard\", \"‚úÖ Operational\" if setup_results.get(\"dashboard\", {}).get(\"success\") else \"‚ùå Failed\"),\n",
    "            (\"Lakehouse Monitoring\", \"‚úÖ Enabled\" if setup_results.get(\"lakehouse_monitoring\", {}).get(\"success\") else \"‚ö†Ô∏è  Optional\")\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüìä COMPONENT STATUS:\")\n",
    "        for component, status in components:\n",
    "            print(f\"   {component:.<25} {status}\")\n",
    "        \n",
    "        # Monitoring assets created\n",
    "        print(f\"\\nüóÇÔ∏è  MONITORING ASSETS (in {self.schema_name}):\")\n",
    "        if setup_results.get(\"drift_detection\", {}).get(\"success\"):\n",
    "            print(\"   ‚úÖ healthcare_drift_detection (view)\")\n",
    "        if setup_results.get(\"alerts\", {}).get(\"success\"):\n",
    "            print(\"   ‚úÖ healthcare_model_alerts (view)\")\n",
    "        if setup_results.get(\"dashboard\", {}).get(\"success\"):\n",
    "            print(\"   ‚úÖ model_performance_dashboard (view)\")\n",
    "        \n",
    "        # Quick access queries\n",
    "        print(f\"\\nüîç QUICK ACCESS QUERIES:\")\n",
    "        print(f\"   ‚Ä¢ Check recent drift: SELECT * FROM {self.schema_name}.healthcare_drift_detection LIMIT 5\")\n",
    "        print(f\"   ‚Ä¢ View active alerts: SELECT * FROM {self.schema_name}.healthcare_model_alerts\")\n",
    "        print(f\"   ‚Ä¢ Executive summary: SELECT * FROM {self.schema_name}.model_performance_dashboard\")\n",
    "        \n",
    "        # Next steps\n",
    "        print(f\"\\nüéØ RECOMMENDED NEXT STEPS:\")\n",
    "        if setup_results.get(\"foundation\", {}).get(\"recent_predictions\", False):\n",
    "            print(\"   1. ‚úÖ You have recent prediction data - monitoring is active\")\n",
    "        else:\n",
    "            print(\"   1. üîÑ Run batch inference to generate fresh monitoring data\")\n",
    "        \n",
    "        print(\"   2. üìà Review the performance dashboard for baseline insights\")\n",
    "        print(\"   3. üö® Set up notification channels for critical alerts\")\n",
    "        print(\"   4. üìÖ Schedule automated monitoring reports\")\n",
    "        print(\"   5. üîÑ Connect monitoring to your retraining pipeline\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 75)\n",
    "\n",
    "\n",
    "# Example usage with the unified schema approach\n",
    "print(\"üöÄ Initializing Healthcare Model Monitoring System\")\n",
    "print(\"   Using unified juan_dev.ml schema for all ML assets\")\n",
    "\n",
    "# Create the monitor with unified schema\n",
    "monitor = HealthcareModelMonitor(\n",
    "    model_name=\"juan_dev.ml.healthcare_insurance_model\",\n",
    "    baseline_table=\"juan_dev.ml.insurance_silver\",      # Your training data\n",
    "    monitoring_table=\"juan_dev.ml.insurance_predictions\" # Your prediction results\n",
    ")\n",
    "\n",
    "# Option 1: Run diagnostics first (recommended)\n",
    "print(\"Running diagnostics to check system readiness...\")\n",
    "diagnostic_results = monitor.diagnose_and_fix_setup_issues()\n",
    "\n",
    "# Option 2: If diagnostics show you're ready, run the quick setup\n",
    "if diagnostic_results[\"ready_for_setup\"]:\n",
    "    print(\"System ready! Running monitoring setup...\")\n",
    "    setup_results = monitor.setup_complete_monitoring_system()\n",
    "else:\n",
    "    print(\"Please address the diagnostic issues first, then run setup\")\n",
    "\n",
    "# Quick verification queries you can run\n",
    "print(\"\\nüîß VERIFICATION COMMANDS:\")\n",
    "print(\"Run these to verify your monitoring system:\")\n",
    "print()\n",
    "print(\"# Check drift detection\")\n",
    "print(\"display(spark.sql('SELECT * FROM juan_dev.ml.healthcare_drift_detection ORDER BY prediction_date DESC LIMIT 5'))\")\n",
    "print()\n",
    "print(\"# Check for alerts\") \n",
    "print(\"display(spark.sql('SELECT * FROM juan_dev.ml.healthcare_model_alerts'))\")\n",
    "print()\n",
    "print(\"# View executive dashboard\")\n",
    "print(\"display(spark.sql('SELECT * FROM juan_dev.ml.model_performance_dashboard'))\")\n",
    "print()\n",
    "print(\"# List all monitoring views\")\n",
    "print(\"display(spark.sql('SHOW TABLES IN juan_dev.ml LIKE \\\"*healthcare*\\\" OR LIKE \\\"*monitoring*\\\" OR LIKE \\\"*dashboard*\\\"'))\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8908198917774838,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "insurance-model-monitor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
