{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f69e7c31-689d-428c-b80f-44082ee024c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering import FeatureLookup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Configure Unity Catalog integration\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_experiment(\"/Users/juan.lamadrid@databricks.com/experiments/insurance_cost_prediction_eda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df03e999-89ee-49c6-ae15-ba9f78450592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class HealthcareInsuranceModel:\n",
    "    \"\"\"\n",
    "    Updated healthcare insurance model for new schema focused on health risk prediction.\n",
    "    This model predicts health_risk_score instead of charges.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fe = FeatureEngineeringClient()\n",
    "        self.model_pipeline = None\n",
    "        \n",
    "    def prepare_training_data(self):\n",
    "        \"\"\"Prepare training dataset using new healthcare schema\"\"\"\n",
    "        # Load base training data from new schema - filter for current records\n",
    "        base_df = spark.table(\"juan_dev.healthcare_data.dim_patients\").filter(col(\"is_current_record\") == True)\n",
    "\n",
    "        feature_table_name=\"juan_dev.healthcare_data.ml_insurance_features\"\n",
    "\n",
    "        # Define feature lookups for engineered features\n",
    "        feature_lookups = [\n",
    "            FeatureLookup(\n",
    "                table_name=feature_table_name,\n",
    "                lookup_key=\"customer_id\",\n",
    "                feature_name=\"age_risk_score\"\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=feature_table_name,\n",
    "                lookup_key=\"customer_id\",\n",
    "                feature_name=\"smoking_impact\"\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=feature_table_name,\n",
    "                lookup_key=\"customer_id\",\n",
    "                feature_name=\"family_size_factor\"\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=feature_table_name,\n",
    "                lookup_key=\"customer_id\",\n",
    "                feature_name=\"regional_multiplier\"\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=feature_table_name,\n",
    "                lookup_key=\"customer_id\",\n",
    "                feature_name=\"health_risk_composite\"\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=feature_table_name,\n",
    "                lookup_key=\"customer_id\",\n",
    "                feature_name=\"data_quality_score\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Create training set with automatic feature joining\n",
    "        # Use health_risk_score as the new label instead of charges\n",
    "        training_set = self.fe.create_training_set(\n",
    "            df=base_df.withColumn(\"customer_id\", col(\"patient_natural_key\")),\n",
    "            feature_lookups=feature_lookups,\n",
    "            label=\"health_risk_score\",\n",
    "            exclude_columns=[\"timestamp\", \"ingestion_timestamp\", \"effective_from_date\", \"effective_to_date\"]\n",
    "        )\n",
    "\n",
    "        return training_set\n",
    "    \n",
    "    def create_preprocessing_pipeline(self):\n",
    "        \"\"\"\n",
    "        Create preprocessing pipeline for new schema fields\n",
    "        \"\"\"\n",
    "        \n",
    "        # Updated feature columns for new schema\n",
    "        categorical_features = ['patient_sex', 'patient_region']  # Use new schema column names\n",
    "        numerical_features = [\n",
    "            'age_risk_score', 'smoking_impact', 'family_size_factor', \n",
    "            'health_risk_composite', 'regional_multiplier', 'data_quality_score'\n",
    "        ]\n",
    "        \n",
    "        # Create preprocessing steps\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_features),\n",
    "                ('cat', LabelEncoder(), categorical_features)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "        \n",
    "        return preprocessor, categorical_features, numerical_features\n",
    "    \n",
    "    def train_model(self, training_set, model_type=\"random_forest\"):\n",
    "        \"\"\"Train healthcare risk prediction model with new schema\"\"\"\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"healthcare_risk_model_{model_type}_new_schema\"):\n",
    "            # Load training data\n",
    "            training_df = training_set.load_df().toPandas()\n",
    "            \n",
    "            print(f\"Training data shape: {training_df.shape}\")\n",
    "            print(f\"Training data columns: {training_df.columns.tolist()}\")\n",
    "            \n",
    "            # Create preprocessing pipeline\n",
    "            preprocessor, categorical_features, numerical_features = self.create_preprocessing_pipeline()\n",
    "            \n",
    "            # Define all feature columns we'll use\n",
    "            feature_columns = numerical_features + categorical_features\n",
    "            \n",
    "            # Prepare feature matrix and target (health_risk_score instead of charges)\n",
    "            X = training_df[feature_columns]\n",
    "            y = training_df['health_risk_score']  # Updated target variable\n",
    "            \n",
    "            print(f\"Feature columns: {feature_columns}\")\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "            print(f\"Target variable stats: mean={y.mean():.2f}, std={y.std():.2f}, min={y.min()}, max={y.max()}\")\n",
    "            \n",
    "            # Handle categorical encoding manually\n",
    "            X_processed = X.copy()\n",
    "            label_encoders = {}\n",
    "            \n",
    "            # Manually encode categorical features and store encoders\n",
    "            for feature in categorical_features:\n",
    "                le = LabelEncoder()\n",
    "                X_processed[feature] = le.fit_transform(X[feature].astype(str))\n",
    "                label_encoders[feature] = le\n",
    "            \n",
    "            # StandardScaler for all features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_processed)\n",
    "            \n",
    "            # Train-test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Select model based on type\n",
    "            if model_type == \"random_forest\":\n",
    "                base_model = RandomForestRegressor(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=10,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    random_state=42\n",
    "                )\n",
    "            else:  # gradient_boosting\n",
    "                base_model = GradientBoostingRegressor(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,\n",
    "                    random_state=42\n",
    "                )\n",
    "            \n",
    "            # Custom pipeline for new schema\n",
    "            class HealthcareRiskPipeline:\n",
    "                def __init__(self, label_encoders, scaler, model, feature_columns):\n",
    "                    self.label_encoders = label_encoders\n",
    "                    self.scaler = scaler\n",
    "                    self.model = model\n",
    "                    self.feature_columns = feature_columns\n",
    "                    self.categorical_features = list(label_encoders.keys())\n",
    "                    \n",
    "                def fit(self, X, y):\n",
    "                    return self.model.fit(X, y)\n",
    "                    \n",
    "                def predict(self, X):\n",
    "                    # Apply the same preprocessing steps as training\n",
    "                    X_processed = X[self.feature_columns].copy()\n",
    "                    \n",
    "                    # Encode categorical features\n",
    "                    for feature in self.categorical_features:\n",
    "                        if feature in X_processed.columns:\n",
    "                            try:\n",
    "                                X_processed[feature] = self.label_encoders[feature].transform(\n",
    "                                    X_processed[feature].astype(str)\n",
    "                                )\n",
    "                            except ValueError as e:\n",
    "                                print(f\"Warning: Unknown category in {feature}, using fallback\")\n",
    "                                most_frequent = 0\n",
    "                                X_processed[feature] = X_processed[feature].apply(\n",
    "                                    lambda x: most_frequent if x not in self.label_encoders[feature].classes_ \n",
    "                                    else self.label_encoders[feature].transform([str(x)])[0]\n",
    "                                )\n",
    "                    \n",
    "                    # Scale features\n",
    "                    X_scaled = self.scaler.transform(X_processed)\n",
    "                    \n",
    "                    # Make prediction\n",
    "                    return self.model.predict(X_scaled)\n",
    "                    \n",
    "                def get_params(self, deep=True):\n",
    "                    return self.model.get_params(deep)\n",
    "                    \n",
    "                def set_params(self, **params):\n",
    "                    return self.model.set_params(**params)\n",
    "            \n",
    "            # Create the custom pipeline\n",
    "            healthcare_pipeline = HealthcareRiskPipeline(\n",
    "                label_encoders=label_encoders,\n",
    "                scaler=scaler,\n",
    "                model=base_model,\n",
    "                feature_columns=feature_columns\n",
    "            )\n",
    "            \n",
    "            # Fit the pipeline\n",
    "            healthcare_pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Store the pipeline\n",
    "            self.model_pipeline = healthcare_pipeline\n",
    "            \n",
    "            # Model evaluation\n",
    "            y_pred = healthcare_pipeline.predict(training_df[feature_columns])\n",
    "            y_test_pred = base_model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            r2 = r2_score(y_test, y_test_pred)\n",
    "            mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "            \n",
    "            # Cross-validation on scaled data\n",
    "            cv_scores = cross_val_score(base_model, X_scaled, y, cv=5, scoring='r2')\n",
    "            \n",
    "            # Healthcare-specific metrics for risk prediction\n",
    "            high_risk_threshold = training_df['health_risk_score'].quantile(0.95)\n",
    "            high_risk_accuracy = self._evaluate_high_risk_predictions(\n",
    "                y_test, y_test_pred, high_risk_threshold\n",
    "            )\n",
    "            \n",
    "            # Log parameters and metrics\n",
    "            mlflow.log_params({\n",
    "                \"model_type\": model_type,\n",
    "                \"n_features\": len(feature_columns),\n",
    "                \"training_samples\": len(X_train),\n",
    "                \"test_samples\": len(X_test),\n",
    "                \"preprocessing\": \"custom_pipeline_new_schema\",\n",
    "                \"target_variable\": \"health_risk_score\",\n",
    "                \"schema_version\": \"healthcare_v2\"\n",
    "            })\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                \"r2_score\": r2,\n",
    "                \"mean_absolute_error\": mae,\n",
    "                \"root_mean_squared_error\": rmse,\n",
    "                \"cv_r2_mean\": cv_scores.mean(),\n",
    "                \"cv_r2_std\": cv_scores.std(),\n",
    "                \"high_risk_accuracy\": high_risk_accuracy,\n",
    "                \"target_mean\": y.mean(),\n",
    "                \"target_std\": y.std()\n",
    "            })\n",
    "            \n",
    "            # Log the complete pipeline with feature engineering integration\n",
    "            model_info = self.fe.log_model(\n",
    "                model=healthcare_pipeline,\n",
    "                artifact_path=\"model\",\n",
    "                flavor=mlflow.sklearn,\n",
    "                training_set=training_set,\n",
    "                registered_model_name=\"juan_dev.healthcare_data.insurance_model\",\n",
    "                metadata={\n",
    "                    \"algorithm\": model_type,\n",
    "                    \"preprocessing\": \"embedded_pipeline\",\n",
    "                    \"healthcare_compliance\": \"HIPAA_ready\",\n",
    "                    \"model_purpose\": \"health_risk_prediction\",\n",
    "                    \"feature_count\": len(feature_columns),\n",
    "                    \"training_data_size\": len(training_df),\n",
    "                    \"categorical_features\": categorical_features,\n",
    "                    \"numerical_features\": numerical_features,\n",
    "                    \"schema_version\": \"healthcare_v2\",\n",
    "                    \"target_variable\": \"health_risk_score\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            return model_info\n",
    "    \n",
    "    def _evaluate_high_risk_predictions(self, y_true, y_pred, threshold):\n",
    "        \"\"\"Evaluate model performance on high-risk patients\"\"\"\n",
    "        high_risk_true = y_true >= threshold\n",
    "        high_risk_pred = y_pred >= threshold\n",
    "        return (high_risk_true == high_risk_pred).mean()\n",
    "\n",
    "\n",
    "# Example usage with new schema\n",
    "print(\"Starting healthcare risk model training with new schema...\")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = HealthcareInsuranceModel()\n",
    "\n",
    "# Prepare training data from new schema\n",
    "print(\"Preparing training data with new healthcare schema...\")\n",
    "training_set = trainer.prepare_training_data()\n",
    "\n",
    "# Train the model for health risk prediction\n",
    "print(\"Training Random Forest model for health risk prediction...\")\n",
    "rf_model_info = trainer.train_model(training_set, \"random_forest\")\n",
    "\n",
    "print(\"Health risk model training completed successfully!\")\n",
    "# print(f\"Model version: {rf_model_info.model_version}\")\n",
    "# print(f\"Model URI: {rf_model_info.model_uri}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "insurance-model-train",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
