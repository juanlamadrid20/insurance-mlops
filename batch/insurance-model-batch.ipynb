{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd3fb4e-ab5c-486b-a8e0-85f6a9d17292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "import mlflow.pyfunc\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, FloatType, DoubleType\n",
    "\n",
    "class HealthcareBatchInference:\n",
    "    \"\"\"\n",
    "    Fixed batch inference class that properly aligns with feature engineering and training.\n",
    "    Uses dim_patients table and customer_id key mapping like the other notebooks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"juan_dev.healthcare_data.insurance_model\", model_alias=\"champion\"):\n",
    "        self.model_name = model_name\n",
    "        self.model_alias = model_alias\n",
    "        self.fe = FeatureEngineeringClient()\n",
    "        \n",
    "        # Spark optimization for batch processing\n",
    "        spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "        spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"10000\")\n",
    "    \n",
    "    def run_batch_inference(self, input_table=\"juan_dev.healthcare_data.dim_patients\", output_table=None):\n",
    "        \"\"\"Execute batch inference using same approach as feature engineering and training\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Load model from Unity Catalog\n",
    "            model_uri = f\"models:/{self.model_name}@{self.model_alias}\"\n",
    "            \n",
    "            # Get model version info\n",
    "            client = mlflow.MlflowClient()\n",
    "            model_version_info = client.get_model_version_by_alias(self.model_name, self.model_alias)\n",
    "            model_version = model_version_info.version\n",
    "            \n",
    "            print(f\"Loading model version {model_version} from {model_uri}\")\n",
    "            \n",
    "            # Load input data from dim_patients - filter for current records (same as training)\n",
    "            input_df = spark.table(input_table).filter(col(\"is_current_record\") == True)\n",
    "            print(f\"Input data shape: {input_df.count()} rows, {len(input_df.columns)} columns\")\n",
    "            print(f\"Input columns: {sorted(input_df.columns)}\")\n",
    "            \n",
    "            # Validate required columns are present (dim_patients schema)\n",
    "            required_base_columns = [\n",
    "                'patient_natural_key', 'patient_sex', 'patient_region', 'patient_smoking_status', \n",
    "                'patient_age_category', 'patient_bmi_category', 'patient_family_size_category',\n",
    "                'health_risk_score', 'is_current_record'\n",
    "            ]\n",
    "            available_columns = [col for col in required_base_columns if col in input_df.columns]\n",
    "            missing_columns = [col for col in required_base_columns if col not in input_df.columns]\n",
    "            \n",
    "            print(f\"Required columns for dim_patients table: {required_base_columns}\")\n",
    "            print(f\"Available required columns: {available_columns}\")\n",
    "            print(f\"Missing columns: {missing_columns}\")\n",
    "            \n",
    "            if missing_columns:\n",
    "                print(f\"ERROR: Input data is missing required columns: {missing_columns}\")\n",
    "                print(f\"All available columns in input table: {sorted(input_df.columns)}\")\n",
    "                raise ValueError(f\"DataFrame is missing required columns {missing_columns}. Check table structure.\")\n",
    "            \n",
    "            # Prepare data exactly like feature engineering notebook\n",
    "            # This creates the customer_id key that the model expects\n",
    "            input_df_prepared = (\n",
    "                input_df\n",
    "                # Create customer_id from patient_natural_key (CRITICAL - matches feature engineering)\n",
    "                .withColumn(\"customer_id\", col(\"patient_natural_key\"))\n",
    "                \n",
    "                # Map categorical fields back to numeric for ML compatibility (matches feature engineering exactly)\n",
    "                .withColumn(\"age\",\n",
    "                           expr(\"CASE WHEN patient_age_category = 'YOUNG' THEN 25 \" +\n",
    "                                \"WHEN patient_age_category = 'ADULT' THEN 35 \" +\n",
    "                                \"WHEN patient_age_category = 'MIDDLE_AGED' THEN 45 \" +\n",
    "                                \"WHEN patient_age_category = 'SENIOR' THEN 60 \" +\n",
    "                                \"ELSE 70 END\"))\n",
    "                \n",
    "                .withColumn(\"bmi\",\n",
    "                           expr(\"CASE WHEN patient_bmi_category = 'UNDERWEIGHT' THEN 17.5 \" +\n",
    "                                \"WHEN patient_bmi_category = 'NORMAL' THEN 22.5 \" +\n",
    "                                \"WHEN patient_bmi_category = 'OVERWEIGHT' THEN 27.5 \" +\n",
    "                                \"ELSE 32.5 END\"))\n",
    "                \n",
    "                .withColumn(\"children\",\n",
    "                           expr(\"CASE WHEN patient_family_size_category = 'SINGLE' THEN 0 \" +\n",
    "                                \"WHEN patient_family_size_category = 'COUPLE' THEN 0 \" +\n",
    "                                \"WHEN patient_family_size_category = 'SMALL_FAMILY' THEN 1 \" +\n",
    "                                \"WHEN patient_family_size_category = 'MEDIUM_FAMILY' THEN 2 \" +\n",
    "                                \"ELSE 4 END\"))\n",
    "                \n",
    "                # Convert smoking status to boolean (matches feature engineering)\n",
    "                .withColumn(\"smoker\", col(\"patient_smoking_status\") == \"SMOKER\")\n",
    "                \n",
    "                # Use region and sex directly (matches feature engineering)\n",
    "                .withColumn(\"region\", col(\"patient_region\"))\n",
    "                .withColumn(\"sex\", col(\"patient_sex\"))\n",
    "            )\n",
    "            \n",
    "            print(\"Data preparation completed successfully\")\n",
    "            print(f\"Prepared data columns: {input_df_prepared.columns}\")\n",
    "            print(f\"Customer ID sample: {[row.customer_id for row in input_df_prepared.select('customer_id').take(3)]}\")\n",
    "            \n",
    "            # Batch scoring with feature engineering integration\n",
    "            # The fe.score_batch will automatically:\n",
    "            # 1. Join with feature table using customer_id\n",
    "            # 2. Apply the model's preprocessing pipeline\n",
    "            # 3. Generate predictions\n",
    "            print(\"Starting batch scoring with feature engineering integration...\")\n",
    "            \n",
    "            predictions_df = self.fe.score_batch(\n",
    "                df=input_df_prepared,\n",
    "                model_uri=model_uri\n",
    "            )\n",
    "            \n",
    "            print(\"Batch scoring completed successfully!\")\n",
    "            print(f\"Predictions shape: {predictions_df.count()} rows\")\n",
    "            print(f\"Prediction columns: {predictions_df.columns}\")\n",
    "            \n",
    "            # Add business logic and metadata\n",
    "            final_predictions = (\n",
    "                predictions_df\n",
    "                .withColumn(\"prediction_timestamp\", current_timestamp())\n",
    "                .withColumn(\"model_version\", lit(model_version))\n",
    "                .withColumn(\"model_name\", lit(self.model_name))\n",
    "                \n",
    "                # Business rule: minimum risk score threshold\n",
    "                .withColumn(\"adjusted_prediction\", \n",
    "                           expr(\"GREATEST(prediction, 10)\"))  # Minimum risk score of 10\n",
    "                \n",
    "                # Risk categorization for business use (adjusted for health risk scores)\n",
    "                .withColumn(\"risk_category\",\n",
    "                           expr(\"CASE WHEN adjusted_prediction < 30 THEN 'low' \" +\n",
    "                                \"WHEN adjusted_prediction < 60 THEN 'medium' \" +\n",
    "                                \"WHEN adjusted_prediction < 85 THEN 'high' \" +\n",
    "                                \"ELSE 'critical' END\"))\n",
    "                \n",
    "                # Confidence intervals (approximate business rules)\n",
    "                .withColumn(\"prediction_lower_bound\", \n",
    "                           expr(\"adjusted_prediction * 0.90\"))\n",
    "                .withColumn(\"prediction_upper_bound\", \n",
    "                           expr(\"adjusted_prediction * 1.10\"))\n",
    "                \n",
    "                # Add risk flags for business decision making\n",
    "                .withColumn(\"high_risk_patient\",\n",
    "                           expr(\"adjusted_prediction > 75 OR risk_category = 'critical'\"))\n",
    "                .withColumn(\"requires_review\", \n",
    "                           expr(\"adjusted_prediction > 90 OR (smoker AND adjusted_prediction > 60)\"))\n",
    "            )\n",
    "            \n",
    "            # Display results for inspection\n",
    "            print(\"Sample predictions:\")\n",
    "            final_predictions.select(\n",
    "                \"customer_id\", \"sex\", \"region\", \"smoker\", \n",
    "                \"prediction\", \"adjusted_prediction\", \"risk_category\"\n",
    "            ).show(10)\n",
    "            \n",
    "            # Save results if output table specified\n",
    "            if output_table:\n",
    "                print(f\"Saving results to {output_table}...\")\n",
    "                (final_predictions\n",
    "                 .write\n",
    "                 .mode(\"overwrite\")\n",
    "                 .option(\"overwriteSchema\", \"true\")\n",
    "                 .saveAsTable(output_table))\n",
    "                print(\"Results saved successfully!\")\n",
    "            \n",
    "            # Log batch inference metrics for monitoring\n",
    "            with mlflow.start_run(run_name=\"batch_inference_health_risk\"):\n",
    "                inference_count = final_predictions.count()\n",
    "                \n",
    "                # Calculate business metrics (adjusted for health risk prediction)\n",
    "                avg_prediction = final_predictions.agg(avg(\"adjusted_prediction\")).collect()[0][0]\n",
    "                high_risk_count = final_predictions.filter(col(\"high_risk_patient\") == True).count()\n",
    "                requires_review_count = final_predictions.filter(col(\"requires_review\") == True).count()\n",
    "                \n",
    "                # Risk category distribution\n",
    "                risk_distribution = final_predictions.groupBy(\"risk_category\").count().collect()\n",
    "                risk_dist_dict = {row.risk_category: row['count'] for row in risk_distribution}\n",
    "                \n",
    "                mlflow.log_metrics({\n",
    "                    \"batch_inference_count\": inference_count,\n",
    "                    \"average_predicted_risk_score\": avg_prediction,\n",
    "                    \"high_risk_patient_count\": high_risk_count,\n",
    "                    \"requires_review_count\": requires_review_count,\n",
    "                    \"high_risk_percentage\": (high_risk_count / inference_count) * 100,\n",
    "                    \"model_version\": float(model_version),\n",
    "                    **{f\"risk_{k}_count\": v for k, v in risk_dist_dict.items()}\n",
    "                })\n",
    "                \n",
    "                print(f\"Logged metrics - Average predicted risk score: {avg_prediction:.2f}\")\n",
    "                print(f\"High risk patients: {high_risk_count} ({high_risk_count/inference_count*100:.1f}%)\")\n",
    "                print(f\"Require review: {requires_review_count} ({requires_review_count/inference_count*100:.1f}%)\")\n",
    "            \n",
    "            return final_predictions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during batch inference: {str(e)}\")\n",
    "            print(\"Troubleshooting steps:\")\n",
    "            print(\"1. Check that the model exists and has the 'champion' alias\")\n",
    "            print(\"2. Verify input data contains all required columns from dim_patients\")\n",
    "            print(\"3. Ensure feature table ml_insurance_features is accessible\")\n",
    "            print(\"4. Check Unity Catalog permissions\")\n",
    "            print(\"5. Verify customer_id mapping from patient_natural_key\")\n",
    "            raise e\n",
    "\n",
    "# Example usage with corrected approach\n",
    "print(\"Initializing FIXED batch inference pipeline...\")\n",
    "\n",
    "batch_inference = HealthcareBatchInference()\n",
    "\n",
    "print(\"Running batch inference on healthcare data using dim_patients table...\")\n",
    "try:\n",
    "    results = batch_inference.run_batch_inference(\n",
    "        input_table=\"juan_dev.healthcare_data.dim_patients\",\n",
    "        output_table=\"juan_dev.healthcare_data.ml_patient_predictions\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Batch Inference Summary ===\")\n",
    "    print(f\"Successfully processed {results.count()} records\")\n",
    "    print(\"Results saved to predictions table\")\n",
    "    \n",
    "    # Show sample results\n",
    "    print(\"\\n=== Sample Predictions ===\")\n",
    "    results.select(\n",
    "        \"customer_id\", \n",
    "        \"adjusted_prediction\",\n",
    "        \"risk_category\",\n",
    "        \"high_risk_patient\",\n",
    "        \"requires_review\"\n",
    "    ).show(5)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Batch inference failed: {e}\")\n",
    "    print(\"Please check the error message above and follow troubleshooting steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78d3d68f-d2c8-4315-b9b2-9fa04e03c66a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4665559814347413,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "insurance-model-batch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
