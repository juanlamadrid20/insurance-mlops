#!/usr/bin/env python3
"""
Test script to validate the ML-prefixed monitoring system
This validates the simplified healthcare model monitoring setup
"""

def test_ml_monitoring_views():
    """Test that all ML monitoring views are accessible and return data"""
    
    print("ğŸ§ª Testing ML Monitoring Views")
    print("=" * 50)
    
    # ML monitoring views to test
    views_to_test = [
        "juan_dev.healthcare_data.ml_drift_monitor",
        "juan_dev.healthcare_data.ml_monitoring_summary", 
        "juan_dev.healthcare_data.ml_model_alerts"
    ]
    
    results = {}
    
    for view_name in views_to_test:
        print(f"\nğŸ” Testing: {view_name}")
        
        try:
            # Test basic access
            df = spark.table(view_name)
            row_count = df.count()
            columns = df.columns
            
            print(f"   âœ… Access: SUCCESS")
            print(f"   ğŸ“Š Rows: {row_count:,}")
            print(f"   ğŸ“‹ Columns: {len(columns)} ({', '.join(columns[:5])}{'...' if len(columns) > 5 else ''})")
            
            # Show sample data if available
            if row_count > 0:
                print(f"   ğŸ“„ Sample data:")
                df.limit(3).show(truncate=False)
            else:
                print(f"   âš ï¸  No data found (may be expected for recent periods)")
            
            results[view_name] = {
                "accessible": True,
                "row_count": row_count,
                "columns": len(columns)
            }
            
        except Exception as e:
            print(f"   âŒ Error: {str(e)}")
            results[view_name] = {
                "accessible": False, 
                "error": str(e)
            }
    
    print(f"\nğŸ“‹ Test Summary:")
    print("-" * 30)
    
    accessible_count = sum(1 for r in results.values() if r.get("accessible", False))
    total_count = len(results)
    
    print(f"Views accessible: {accessible_count}/{total_count}")
    
    for view_name, result in results.items():
        status = "âœ…" if result.get("accessible", False) else "âŒ"
        short_name = view_name.split(".")[-1]  # Get just the view name
        print(f"   {status} {short_name}")
    
    return results

def test_source_tables():
    """Test that source tables are accessible"""
    
    print("\nğŸ—ƒï¸  Testing Source Tables")
    print("=" * 50)
    
    source_tables = [
        "juan_dev.healthcare_data.silver_patients",
        "juan_dev.healthcare_data.ml_patient_predictions"
    ]
    
    for table_name in source_tables:
        try:
            df = spark.table(table_name)
            row_count = df.count()
            print(f"âœ… {table_name}: {row_count:,} records")
            
            # Show a few columns to verify schema
            columns = df.columns[:8]  # First 8 columns
            print(f"   Columns: {', '.join(columns)}...")
            
        except Exception as e:
            print(f"âŒ {table_name}: Error - {str(e)}")

def run_monitoring_validation():
    """Run complete monitoring validation"""
    
    print("ğŸš€ ML Monitoring System Validation")
    print("ğŸ¯ Objective: Validate lakehouse monitoring fundamentals")
    print("ğŸ·ï¸  Asset Naming: ML-prefixed monitoring views")
    print("=" * 70)
    
    # Test 1: Source tables
    test_source_tables()
    
    # Test 2: ML monitoring views
    view_results = test_ml_monitoring_views()
    
    # Test 3: Basic monitoring queries
    print(f"\nğŸ” Testing Basic Monitoring Queries")
    print("=" * 50)
    
    try:
        # Test drift monitoring query
        print("Testing drift monitoring query...")
        drift_query = """
        SELECT 
            prediction_date,
            daily_predictions,
            avg_prediction,
            volume_status
        FROM juan_dev.healthcare_data.ml_drift_monitor 
        ORDER BY prediction_date DESC 
        LIMIT 5
        """
        
        drift_df = spark.sql(drift_query)
        drift_count = drift_df.count()
        
        if drift_count > 0:
            print(f"âœ… Drift monitoring: {drift_count} recent periods")
            drift_df.show()
        else:
            print("âš ï¸  Drift monitoring: No recent data (may be expected)")
            
    except Exception as e:
        print(f"âŒ Drift monitoring query failed: {e}")
    
    # Overall assessment
    print(f"\nğŸ‰ Validation Complete!")
    print("=" * 50)
    
    accessible_views = sum(1 for r in view_results.values() if r.get("accessible", False))
    total_views = len(view_results)
    
    if accessible_views == total_views:
        print("âœ… All ML monitoring views are working correctly!")
        print("ğŸ¯ Lakehouse monitoring fundamentals validated successfully")
        print("ğŸš€ Ready to add business logic incrementally")
    else:
        print(f"âš ï¸  {accessible_views}/{total_views} views working - review issues above")
        print("ğŸ”§ Fix any view creation issues before proceeding")
    
    print(f"\nğŸ“Š ML Asset Summary:")
    print("   â€¢ ml_drift_monitor: Daily prediction metrics and drift detection")
    print("   â€¢ ml_monitoring_summary: Overall model performance summary")  
    print("   â€¢ ml_model_alerts: Automated alerting for anomalies")
    
    return view_results

if __name__ == "__main__":
    # This would run if executed as a script
    # In Databricks, you would run the functions directly
    print("ML Monitoring Validation Script")
    print("Run: run_monitoring_validation() in Databricks")
    test_ml_monitoring_views()
    run_monitoring_validation()