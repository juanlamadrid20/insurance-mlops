{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Validation Notebook for Healthcare Insurance MLOps\n",
    "# This notebook validates batch inference results\n",
    "\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Get parameters\n",
    "dbutils.widgets.text(\"catalog\", \"juan_dev\", \"Unity Catalog name\")\n",
    "dbutils.widgets.text(\"ml_schema\", \"ml\", \"ML Schema name\")\n",
    "dbutils.widgets.text(\"predictions_table\", \"\", \"Predictions table\")\n",
    "dbutils.widgets.text(\"batch_date\", \"\", \"Batch date (YYYY-MM-DD)\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "ml_schema = dbutils.widgets.get(\"ml_schema\")\n",
    "predictions_table = dbutils.widgets.get(\"predictions_table\")\n",
    "batch_date = dbutils.widgets.get(\"batch_date\")\n",
    "\n",
    "print(f\"Validating inference results for {predictions_table} on {batch_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate predictions\n",
    "try:\n",
    "    predictions_df = spark.table(predictions_table)\n",
    "    \n",
    "    # Filter for today's predictions if batch_date provided\n",
    "    if batch_date:\n",
    "        daily_predictions = predictions_df.filter(\n",
    "            date_format(col(\"prediction_timestamp\"), \"yyyy-MM-dd\") == batch_date\n",
    "        )\n",
    "    else:\n",
    "        daily_predictions = predictions_df.filter(\n",
    "            col(\"prediction_timestamp\") >= current_date()\n",
    "        )\n",
    "    \n",
    "    prediction_count = daily_predictions.count()\n",
    "    print(f\"✅ Found {prediction_count:,} predictions for validation\")\n",
    "    \n",
    "    if prediction_count == 0:\n",
    "        print(\"❌ No predictions found for validation\")\n",
    "        dbutils.notebook.exit(json.dumps({\"status\": \"FAILED\", \"message\": \"No predictions found\"}))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not load predictions: {str(e)}\")\n",
    "    dbutils.notebook.exit(json.dumps({\"status\": \"FAILED\", \"message\": str(e)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate prediction quality\n",
    "try:\n",
    "    # Check for null predictions\n",
    "    null_predictions = daily_predictions.filter(col(\"adjusted_prediction\").isNull()).count()\n",
    "    \n",
    "    if null_predictions > 0:\n",
    "        print(f\"❌ Found {null_predictions} null predictions\")\n",
    "        dbutils.notebook.exit(json.dumps({\"status\": \"FAILED\", \"message\": f\"{null_predictions} null predictions\"}))\n",
    "    else:\n",
    "        print(f\"✅ No null predictions found\")\n",
    "    \n",
    "    # Check prediction range (risk scores should be 0-100)\n",
    "    prediction_stats = daily_predictions.agg(\n",
    "        min(\"adjusted_prediction\").alias(\"min_pred\"),\n",
    "        max(\"adjusted_prediction\").alias(\"max_pred\"),\n",
    "        avg(\"adjusted_prediction\").alias(\"avg_pred\"),\n",
    "        stddev(\"adjusted_prediction\").alias(\"std_pred\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    min_pred = prediction_stats.min_pred\n",
    "    max_pred = prediction_stats.max_pred\n",
    "    avg_pred = prediction_stats.avg_pred\n",
    "    std_pred = prediction_stats.std_pred\n",
    "    \n",
    "    print(f\"Prediction range: {min_pred:.2f} - {max_pred:.2f}\")\n",
    "    print(f\"Average prediction: {avg_pred:.2f} ± {std_pred:.2f}\")\n",
    "    \n",
    "    # Validate reasonable ranges\n",
    "    if min_pred < 0 or max_pred > 200:  # Allow some flexibility for different target types\n",
    "        print(f\"⚠️  Predictions outside expected range: {min_pred:.2f} - {max_pred:.2f}\")\n",
    "    else:\n",
    "        print(f\"✅ Predictions within reasonable range\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Prediction validation failed: {str(e)}\")\n",
    "    dbutils.notebook.exit(json.dumps({\"status\": \"FAILED\", \"message\": str(e)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check business logic validation\n",
    "try:\n",
    "    # Risk category distribution\n",
    "    risk_distribution = daily_predictions.groupBy(\"risk_category\").count().collect()\n",
    "    \n",
    "    print(\"Risk category distribution:\")\n",
    "    for row in risk_distribution:\n",
    "        category = row.risk_category\n",
    "        count = row['count']\n",
    "        percentage = (count / prediction_count) * 100\n",
    "        print(f\"  {category}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Check for high-risk flags\n",
    "    high_risk_count = daily_predictions.filter(col(\"high_risk_patient\") == True).count()\n",
    "    high_risk_pct = (high_risk_count / prediction_count) * 100\n",
    "    \n",
    "    print(f\"High-risk patients: {high_risk_count:,} ({high_risk_pct:.1f}%)\")\n",
    "    \n",
    "    # Validate business rules\n",
    "    if high_risk_pct > 50:  # More than 50% high-risk seems unusual\n",
    "        print(f\"⚠️  High percentage of high-risk patients: {high_risk_pct:.1f}%\")\n",
    "    elif high_risk_pct < 1:  # Less than 1% high-risk also seems unusual\n",
    "        print(f\"⚠️  Very low percentage of high-risk patients: {high_risk_pct:.1f}%\")\n",
    "    else:\n",
    "        print(f\"✅ High-risk patient percentage within reasonable range\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Business logic validation failed: {str(e)}\")\n",
    "    dbutils.notebook.exit(json.dumps({\"status\": \"FAILED\", \"message\": str(e)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation summary\n",
    "validation_summary = {\n",
    "    \"status\": \"SUCCESS\",\n",
    "    \"prediction_count\": prediction_count,\n",
    "    \"avg_prediction\": float(avg_pred),\n",
    "    \"high_risk_percentage\": float(high_risk_pct),\n",
    "    \"validation_date\": batch_date or str(date.today())\n",
    "}\n",
    "\n",
    "print(f\"\\n=== Validation Summary ===\")\n",
    "print(f\"✅ Inference validation completed successfully\")\n",
    "print(f\"Predictions validated: {prediction_count:,}\")\n",
    "print(f\"Average prediction: {avg_pred:.2f}\")\n",
    "print(f\"High-risk patients: {high_risk_pct:.1f}%\")\n",
    "\n",
    "dbutils.notebook.exit(json.dumps(validation_summary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}